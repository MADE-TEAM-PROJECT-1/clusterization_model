{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Doc2Vec on scientific articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook replicates the **Document Embedding with Paragraph Vectors** paper, http://arxiv.org/abs/1507.07998.\n",
    "\n",
    "In that paper, the authors only showed results from the DBOW (\"distributed bag of words\") mode, trained on the article dataset. Here we replicate this experiment using not only DBOW, but also the DM (\"distributed memory\") mode of the Paragraph Vector algorithm aka Doc2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the necessary modules and set up logging. The code below assumes Python 3.7+ and Gensim 4.0+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "\n",
    "import smart_open\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_DROP = ['year', 'n_citation', 'references', 'authors','venue', 'lang', 'page_start', 'page_end', 'volume',\n",
    "       'issue', 'issn', 'isbn', 'doi', 'pdf', 'url']\n",
    "RANDOM_STATE = 42\n",
    "NUM_PARTS = 5\n",
    "\n",
    "def get_text_data(file_path):\n",
    "    \n",
    "    data = pd.read_json(file_path, dtype={'title': 'string', 'abstract': 'string'})\n",
    "    data.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "    data['abstract'].replace('', np.nan, inplace=True)\n",
    "    data = data.dropna(subset=['keywords', 'abstract', 'title', 'fos'])\n",
    "    data['text'] = data[['title', 'abstract']].apply(lambda row: ' '.join(row.astype(str)), axis=1).astype('string')\n",
    "    data.drop(['title', 'abstract'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1124438 entries, 0 to 1124437\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count    Dtype \n",
      "---  ------    --------------    ----- \n",
      " 0   _id       1124438 non-null  object\n",
      " 1   keywords  1124438 non-null  object\n",
      " 2   fos       1124438 non-null  object\n",
      " 3   text      1124438 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 42.9+ MB\n"
     ]
    }
   ],
   "source": [
    "articles = pd.concat(get_text_data(f'data/part_{i+1}.json') for i in range(NUM_PARTS))\n",
    "articles.reset_index(drop=True, inplace=True)\n",
    "articles.to_json('articles.json')\n",
    "articles.to_csv('articles.csv')\n",
    "articles = pd.read_json('articles.json')\n",
    "\n",
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 231269 entries, 0 to 231268\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   _id       231269 non-null  object\n",
      " 1   keywords  231269 non-null  object\n",
      " 2   fos       231269 non-null  object\n",
      " 3   text      231269 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test_articles = get_text_data('data/part_6.json')\n",
    "test_articles.reset_index(drop=True, inplace=True)\n",
    "test_articles.to_json('articles.json')\n",
    "test_articles = pd.read_json('articles.json')\n",
    "\n",
    "test_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>fos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53e9b036b7602d9703a91d9b</td>\n",
       "      <td>[single class, performance analysis, response ...</td>\n",
       "      <td>[Timing diagram, Sequence diagram, Computer sc...</td>\n",
       "      <td>Applying the UML class diagram in the performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53e9b036b7602d9703a922a3</td>\n",
       "      <td>[grid computing, share geographically, differe...</td>\n",
       "      <td>[Reservation, Preemption, Virtual machine, Sch...</td>\n",
       "      <td>Resource Leasing and the Art of Suspending Vir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e9b036b7602d9703a920d5</td>\n",
       "      <td>[potential cause, entropy rate constancy princ...</td>\n",
       "      <td>[Gapping, Branching factor, Entropy rate, Tree...</td>\n",
       "      <td>Variation of entropy and parse trees of senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e9b036b7602d9703a92304</td>\n",
       "      <td>[database management systems, best-first searc...</td>\n",
       "      <td>[Skyline, Data mining, R-tree, Ranking, Comput...</td>\n",
       "      <td>Skyline ranking for uncertain data with maybe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53e9b036b7602d9703a92101</td>\n",
       "      <td>[State feedback, Closed loop systems, Linear m...</td>\n",
       "      <td>[Iterative method, Control theory, Exponential...</td>\n",
       "      <td>Robust Controller Design of Uncertain Discrete...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  53e9b036b7602d9703a91d9b   \n",
       "1  53e9b036b7602d9703a922a3   \n",
       "2  53e9b036b7602d9703a920d5   \n",
       "3  53e9b036b7602d9703a92304   \n",
       "4  53e9b036b7602d9703a92101   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [single class, performance analysis, response ...   \n",
       "1  [grid computing, share geographically, differe...   \n",
       "2  [potential cause, entropy rate constancy princ...   \n",
       "3  [database management systems, best-first searc...   \n",
       "4  [State feedback, Closed loop systems, Linear m...   \n",
       "\n",
       "                                                 fos  \\\n",
       "0  [Timing diagram, Sequence diagram, Computer sc...   \n",
       "1  [Reservation, Preemption, Virtual machine, Sch...   \n",
       "2  [Gapping, Branching factor, Entropy rate, Tree...   \n",
       "3  [Skyline, Data mining, R-tree, Ranking, Comput...   \n",
       "4  [Iterative method, Control theory, Exponential...   \n",
       "\n",
       "                                                text  \n",
       "0  Applying the UML class diagram in the performa...  \n",
       "1  Resource Leasing and the Art of Suspending Vir...  \n",
       "2  Variation of entropy and parse trees of senten...  \n",
       "3  Skyline ranking for uncertain data with maybe ...  \n",
       "4  Robust Controller Design of Uncertain Discrete...  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd831f6eb4846f99c3d525fddc5e589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=281112), Label(value='0 / 281112')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 9.05 s, total: 34.1 s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def normalize(sentence):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    porter = PorterStemmer()\n",
    "    if isinstance(sentence, list):\n",
    "        return [word.lower() for word in sentence]\n",
    "        #return [porter.stem(word) for word in sentence]\n",
    "    return ' '.join(porter.stem(word) for word in sentence.split())\n",
    "\n",
    "articles = articles.parallel_applymap(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer science', 716471),\n",
       " ('mathematics', 261368),\n",
       " ('artificial intelligence', 216887),\n",
       " ('algorithm', 104301),\n",
       " ('computer vision', 80242),\n",
       " ('data mining', 78938),\n",
       " ('discrete mathematics', 74711),\n",
       " ('computer network', 74309),\n",
       " ('distributed computing', 69909),\n",
       " ('engineering', 66918),\n",
       " ('combinatorics', 62436),\n",
       " ('mathematical optimization', 60434),\n",
       " ('theoretical computer science', 59880),\n",
       " ('pattern recognition', 59719),\n",
       " ('machine learning', 51758),\n",
       " ('world wide web', 49397),\n",
       " ('programming language', 46461),\n",
       " ('information retrieval', 45807),\n",
       " ('control theory', 44805),\n",
       " ('software engineering', 42317),\n",
       " ('multimedia', 35088),\n",
       " ('computer security', 35015),\n",
       " ('knowledge management', 34590),\n",
       " ('software', 33129),\n",
       " ('natural language processing', 31679),\n",
       " ('parallel computing', 31594),\n",
       " ('human–computer interaction', 30237),\n",
       " ('feature extraction', 29798),\n",
       " ('embedded system', 29575),\n",
       " ('artificial neural network', 29138),\n",
       " ('simulation', 28845),\n",
       " ('speech recognition', 28827),\n",
       " ('the internet', 28776),\n",
       " ('electronic engineering', 28384),\n",
       " ('real-time computing', 26670),\n",
       " ('mathematical analysis', 24640),\n",
       " ('image processing', 24399),\n",
       " ('quality of service', 24201),\n",
       " ('information system', 24162),\n",
       " ('genetic algorithm', 23901),\n",
       " ('wireless sensor network', 23295),\n",
       " ('computation', 22757),\n",
       " ('scalability', 22418),\n",
       " ('cluster analysis', 21966),\n",
       " ('internet', 20680),\n",
       " ('fuzzy logic', 20431),\n",
       " ('database', 20412),\n",
       " ('software development', 20397),\n",
       " ('image segmentation', 20337),\n",
       " ('communication channel', 20300)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq = Counter()\n",
    "for index, doc in articles.iterrows():\n",
    "    tag_freq.update(Counter(doc['fos']))\n",
    "    tag_freq.update(Counter(doc['keywords']))\n",
    "\n",
    "tag_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3557260"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1749"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_tags = {tag:tag_freq[tag] for tag in tag_freq if tag_freq[tag] > 1499}\n",
    "len(most_freq_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedCorpus:\n",
    "    def __init__(self, dataframe, min_freq=99):\n",
    "        self.df = dataframe\n",
    "        self.min_freq = min_freq\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for index, row in self.df.iterrows():\n",
    "            kws = {kw for kw in row['keywords'] +  row['fos'] if tag_freq[kw] > self.min_freq}\n",
    "            if len(kws) < 2:\n",
    "                continue\n",
    "            yield TaggedDocument(words=row['text'].split(), tags=list(kws))\n",
    "\n",
    "documents299 = TaggedCorpus(articles, min_freq=299)            \n",
    "documents99 = TaggedCorpus(articles, min_freq=99)  \n",
    "documents29 = TaggedCorpus(articles, min_freq=29) \n",
    "documents599 = TaggedCorpus(articles, min_freq=599)\n",
    "documents1499 = TaggedCorpus(articles, min_freq=1499)\n",
    "#documents = [TaggedDocument(row['text'], [row['_id']]) for index, row in articles.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['environmental science', 'spectrum', 'indexes', 'indexing terms', 'indexation'] :  ['the', 'relationship', 'between', 'canopi', 'paramet', 'and', 'spectrum', 'of', 'winter', 'wheat', 'under', 'differ', 'irrig', 'in', 'hebei', 'province.', 'intern', 'geoscienc', 'and', 'remot', 'sens', 'symposium', 'drought', 'is', 'the', 'first', 'place', 'in', 'all', 'the', 'natur', 'disast', 'in', 'the', 'world.', 'It', 'is', 'especi', 'seriou', 'in', 'north', 'china', 'plain.', 'In', 'thi', 'paper,', 'differ', 'soil', 'water', 'content', 'control', 'level', 'at', 'winter', 'wheat', 'growth', 'stage', 'are', 'perform', 'on', 'gucheng', 'ecological-meteorolog', 'integr', 'observ', 'experi', 'station', 'of', 'cams,', 'china.', 'some', 'canopi', 'parameters,', 'includ', 'growth', 'conditions,', 'dri', 'weight,', 'physiolog', 'paramet', 'and', 'hyperspectr', 'reflectance,', 'are', 'measur', 'from', 'erect', 'stage', 'to', 'milk', 'stage', 'for', 'winter', 'wheat', 'in', '2009.', 'the', 'relationship', 'between', 'canopi', 'paramet', 'and', 'soil', 'rel', 'moisture,', 'canopi', 'water', 'content', 'and', 'water', 'indic', 'of', 'winter', 'wheat', 'are', 'established.', 'the', 'result', 'show', 'that', 'some', 'parameters,', 'such', 'as', 'spad', 'and', 'dri', 'weight', 'of', 'leaves,', 'decreas', 'with', 'the', 'increas', 'of', 'soil', 'rel', 'moisture,', 'while', 'other', 'parameters,', 'includ', 'dri', 'weight', 'of', 'caudexes,', 'abov', 'ground', 'dri', 'weight,', 'height,', 'photosynthesi', 'rate,', 'intercellular', 'CO', '2', 'concentration,', 'stomat', 'conduct', 'and', 'transpir', 'rate,', 'increas', 'correspond', 'to', 'the', 'soil', 'rel', 'moisture.', 'obviou', 'linear', 'relationship', 'between', 'stomat', 'conduct', 'and', 'transpir', 'rate', 'is', 'establish', 'with', '45', 'samples,', 'which', 'R2', 'reach', 'to', '0.6152.', 'finally,', 'the', 'fit', 'equat', 'between', 'canopi', 'water', 'content', 'and', 'water', 'indic', 'are', 'regress', 'with', 'b5,', 'b6', 'and', 'b7', 'of', 'modi', 'bands.', 'the', 'equat', 'are', 'best', 'with', 'b7', 'and', 'worst', 'with', 'b5.', 'So', 'the', 'fit', 'equat', 'with', 'b7', 'can', 'be', 'use', 'to', 'invers', 'the', 'canopi', 'water', 'content', 'of', 'winter', 'wheat', 'use', 'modi', 'or', 'other', 'remot', 'sens', 'imag', 'with', 'similar', 'band', 'rang', 'to', 'modi', 'in', 'hebei', 'province.', '©', '2011', 'ieee.']\n"
     ]
    }
   ],
   "source": [
    "# Load and print the first preprocessed document, as a sanity check = \"input eyeballing\".\n",
    "first_doc = next(iter(documents1499))\n",
    "print(first_doc.tags, ': ', first_doc.words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document seems legit so let's move on to finally training some Doc2vec models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original paper had a vocabulary size of 915,715 word types, so we'll try to match it by setting `max_final_vocab` to 1,000,000 in the Doc2vec constructor.\n",
    "\n",
    "Other critical parameters were left unspecified in the paper, so we'll go with a window size of eight (a prediction window of 8 tokens to either side). It looks like the authors tried vector dimensionality of 100, 300, 1,000 & 10,000 in the paper (with 10k dims performing the best), but I'll only train with 200 dimensions here, to keep the RAM in check on my laptop.\n",
    "\n",
    "Feel free to tinker with these values yourself if you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 17:34:07,138 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-19T17:34:07.138120', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-19 17:34:07,172 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-19T17:34:07.172679', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-19 17:34:07,173 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-19T17:34:07.173916', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-19 17:34:07,174 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-19T17:34:07.174863', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "workers = multiprocessing.cpu_count() - 2  # leave one core for the OS & other stuff\n",
    "\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow29 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow99 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow299 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "\n",
    "\n",
    "# PV-DM: paragraph vector in distributed memory mode\n",
    "model_dm = Doc2Vec(\n",
    "    dm=1, dm_mean=1,  # use average of context word vectors to train DM\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 17:34:14,001 : INFO : collecting all words and their counts\n",
      "2022-10-19 17:34:14,003 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-10-19 17:34:28,033 : INFO : PROGRESS: at example #100000, processed 13973232 words (996004 words/s), 385945 word types, 49025 tags\n",
      "2022-10-19 17:34:41,866 : INFO : PROGRESS: at example #200000, processed 27589815 words (984397 words/s), 636898 word types, 49920 tags\n",
      "2022-10-19 17:34:56,269 : INFO : PROGRESS: at example #300000, processed 42242831 words (1017444 words/s), 851710 word types, 49976 tags\n",
      "2022-10-19 17:35:10,659 : INFO : PROGRESS: at example #400000, processed 56854607 words (1015492 words/s), 1045186 word types, 49980 tags\n",
      "2022-10-19 17:35:25,235 : INFO : PROGRESS: at example #500000, processed 71412120 words (998771 words/s), 1226341 word types, 49980 tags\n",
      "2022-10-19 17:35:40,101 : INFO : PROGRESS: at example #600000, processed 85962511 words (978836 words/s), 1396240 word types, 49980 tags\n",
      "2022-10-19 17:35:54,869 : INFO : PROGRESS: at example #700000, processed 100626352 words (992991 words/s), 1559209 word types, 49980 tags\n",
      "2022-10-19 17:36:09,286 : INFO : PROGRESS: at example #800000, processed 115101028 words (1004042 words/s), 1717067 word types, 49980 tags\n",
      "2022-10-19 17:36:23,739 : INFO : PROGRESS: at example #900000, processed 129345642 words (985644 words/s), 1868555 word types, 49980 tags\n",
      "2022-10-19 17:36:38,418 : INFO : PROGRESS: at example #1000000, processed 143742420 words (980855 words/s), 2015713 word types, 49980 tags\n",
      "2022-10-19 17:36:53,030 : INFO : PROGRESS: at example #1100000, processed 158096788 words (982380 words/s), 2159581 word types, 49980 tags\n",
      "2022-10-19 17:36:56,961 : INFO : collected 2194920 word types and 49980 unique tags from a corpus of 1124438 examples and 161599099 words\n",
      "2022-10-19 17:36:57,887 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=2, effective_min_count=5', 'datetime': '2022-10-19T17:36:57.886963', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:36:57,887 : INFO : Creating a fresh vocabulary\n",
      "2022-10-19 17:36:59,686 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 290617 unique words (13.24% of original 2194920, drops 1904303)', 'datetime': '2022-10-19T17:36:59.686308', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:36:59,687 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 158967837 word corpus (98.37% of original 161599099, drops 2631262)', 'datetime': '2022-10-19T17:36:59.687529', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:37:01,626 : INFO : deleting the raw counts dictionary of 2194920 items\n",
      "2022-10-19 17:37:01,663 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-10-19 17:37:01,664 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 123566164.96006824 word corpus (77.7%% of prior 158967837)', 'datetime': '2022-10-19T17:37:01.664566', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:37:05,098 : INFO : estimated required memory for 290617 words and 200 dimensions: 660275700 bytes\n",
      "2022-10-19 17:37:05,098 : INFO : resetting layer weights\n",
      "2022-10-19 17:37:05,335 : INFO : collecting all words and their counts\n",
      "2022-10-19 17:37:05,337 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 17:37:19,245 : INFO : PROGRESS: at example #100000, processed 13973232 words (1004736 words/s), 385945 word types, 19731 tags\n",
      "2022-10-19 17:37:33,042 : INFO : PROGRESS: at example #200000, processed 27589815 words (986960 words/s), 636898 word types, 19732 tags\n",
      "2022-10-19 17:37:47,127 : INFO : PROGRESS: at example #300000, processed 42242831 words (1040398 words/s), 851710 word types, 19732 tags\n",
      "2022-10-19 17:38:01,498 : INFO : PROGRESS: at example #400000, processed 56854607 words (1016844 words/s), 1045186 word types, 19732 tags\n",
      "2022-10-19 17:38:16,091 : INFO : PROGRESS: at example #500000, processed 71412120 words (997647 words/s), 1226341 word types, 19732 tags\n",
      "2022-10-19 17:38:30,662 : INFO : PROGRESS: at example #600000, processed 85962511 words (998620 words/s), 1396240 word types, 19732 tags\n",
      "2022-10-19 17:38:45,382 : INFO : PROGRESS: at example #700000, processed 100626352 words (996236 words/s), 1559209 word types, 19732 tags\n",
      "2022-10-19 17:38:59,992 : INFO : PROGRESS: at example #800000, processed 115101028 words (990782 words/s), 1717067 word types, 19732 tags\n",
      "2022-10-19 17:39:14,650 : INFO : PROGRESS: at example #900000, processed 129345642 words (971858 words/s), 1868555 word types, 19732 tags\n",
      "2022-10-19 17:39:29,346 : INFO : PROGRESS: at example #1000000, processed 143742420 words (979729 words/s), 2015713 word types, 19732 tags\n",
      "2022-10-19 17:39:44,077 : INFO : PROGRESS: at example #1100000, processed 158096788 words (974465 words/s), 2159581 word types, 19732 tags\n",
      "2022-10-19 17:39:47,786 : INFO : collected 2194920 word types and 19732 unique tags from a corpus of 1124438 examples and 161599099 words\n",
      "2022-10-19 17:39:48,753 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=2, effective_min_count=5', 'datetime': '2022-10-19T17:39:48.753231', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:39:48,754 : INFO : Creating a fresh vocabulary\n",
      "2022-10-19 17:39:50,531 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 290617 unique words (13.24% of original 2194920, drops 1904303)', 'datetime': '2022-10-19T17:39:50.531720', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:39:50,532 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 158967837 word corpus (98.37% of original 161599099, drops 2631262)', 'datetime': '2022-10-19T17:39:50.532529', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:39:52,468 : INFO : deleting the raw counts dictionary of 2194920 items\n",
      "2022-10-19 17:39:52,510 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-10-19 17:39:52,511 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 123566164.96006824 word corpus (77.7%% of prior 158967837)', 'datetime': '2022-10-19T17:39:52.511812', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:39:56,041 : INFO : estimated required memory for 290617 words and 200 dimensions: 630027700 bytes\n",
      "2022-10-19 17:39:56,042 : INFO : resetting layer weights\n",
      "2022-10-19 17:39:56,299 : INFO : collecting all words and their counts\n",
      "2022-10-19 17:39:56,301 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 17:40:09,950 : INFO : PROGRESS: at example #100000, processed 13973232 words (1023841 words/s), 385945 word types, 8152 tags\n",
      "2022-10-19 17:40:23,708 : INFO : PROGRESS: at example #200000, processed 27589815 words (989751 words/s), 636898 word types, 8152 tags\n",
      "2022-10-19 17:40:38,034 : INFO : PROGRESS: at example #300000, processed 42242831 words (1022899 words/s), 851710 word types, 8152 tags\n",
      "2022-10-19 17:40:52,395 : INFO : PROGRESS: at example #400000, processed 56854607 words (1017524 words/s), 1045186 word types, 8152 tags\n",
      "2022-10-19 17:41:06,808 : INFO : PROGRESS: at example #500000, processed 71412120 words (1010074 words/s), 1226341 word types, 8152 tags\n",
      "2022-10-19 17:41:21,377 : INFO : PROGRESS: at example #600000, processed 85962511 words (998780 words/s), 1396240 word types, 8152 tags\n",
      "2022-10-19 17:41:36,028 : INFO : PROGRESS: at example #700000, processed 100626352 words (1000953 words/s), 1559209 word types, 8152 tags\n",
      "2022-10-19 17:41:50,566 : INFO : PROGRESS: at example #800000, processed 115101028 words (995715 words/s), 1717067 word types, 8152 tags\n",
      "2022-10-19 17:42:04,748 : INFO : PROGRESS: at example #900000, processed 129345642 words (1004460 words/s), 1868555 word types, 8152 tags\n",
      "2022-10-19 17:42:18,904 : INFO : PROGRESS: at example #1000000, processed 143742420 words (1017123 words/s), 2015713 word types, 8152 tags\n",
      "2022-10-19 17:42:33,109 : INFO : PROGRESS: at example #1100000, processed 158096788 words (1010528 words/s), 2159581 word types, 8152 tags\n",
      "2022-10-19 17:42:36,661 : INFO : collected 2194920 word types and 8152 unique tags from a corpus of 1124438 examples and 161599099 words\n",
      "2022-10-19 17:42:37,623 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=2, effective_min_count=5', 'datetime': '2022-10-19T17:42:37.623389', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:42:37,624 : INFO : Creating a fresh vocabulary\n",
      "2022-10-19 17:42:39,310 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 290617 unique words (13.24% of original 2194920, drops 1904303)', 'datetime': '2022-10-19T17:42:39.309993', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:42:39,311 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 158967837 word corpus (98.37% of original 161599099, drops 2631262)', 'datetime': '2022-10-19T17:42:39.311100', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:42:41,218 : INFO : deleting the raw counts dictionary of 2194920 items\n",
      "2022-10-19 17:42:41,256 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-10-19 17:42:41,256 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 123566164.96006824 word corpus (77.7%% of prior 158967837)', 'datetime': '2022-10-19T17:42:41.256869', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 17:42:44,692 : INFO : estimated required memory for 290617 words and 200 dimensions: 618447700 bytes\n",
      "2022-10-19 17:42:44,693 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n"
     ]
    }
   ],
   "source": [
    "model_dbow29.build_vocab(documents29, progress_per=100000, )\n",
    "print(model_dbow29)\n",
    "print('---------------------------------------')\n",
    "\n",
    "model_dbow99.build_vocab(documents99, progress_per=100000)\n",
    "print(model_dbow99)\n",
    "print('---------------------------------------')\n",
    "\n",
    "model_dbow299.build_vocab(documents299, progress_per=100000)\n",
    "print(model_dbow299)\n",
    "\n",
    "# Save some time by copying the vocabulary structures from the DBOW model to the DM model.\n",
    "# Both models are built on top of exactly the same data, so there's no need to repeat the vocab-building step.\n",
    "#model_dm.reset_from(model_dbow)\n",
    "#print(model_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 17:42:44,952 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 30 workers on 290617 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-10-19T17:42:44.952305', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2022-10-19 17:42:47,199 : INFO : EPOCH 0 - PROGRESS: at 0.01% examples, 3698 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 17:47:47,242 : INFO : EPOCH 0 - PROGRESS: at 30.88% examples, 136641 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 17:52:47,262 : INFO : EPOCH 0 - PROGRESS: at 60.37% examples, 136103 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 17:57:47,269 : INFO : EPOCH 0 - PROGRESS: at 88.13% examples, 132684 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 17:59:45,155 : INFO : EPOCH 0: training on 161599099 raw words (135843241 effective words) took 1020.2s, 133157 effective words/s\n",
      "2022-10-19 17:59:47,142 : INFO : EPOCH 1 - PROGRESS: at 0.01% examples, 4259 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:04:47,262 : INFO : EPOCH 1 - PROGRESS: at 30.86% examples, 136667 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:09:47,372 : INFO : EPOCH 1 - PROGRESS: at 60.29% examples, 135925 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 18:14:47,382 : INFO : EPOCH 1 - PROGRESS: at 90.27% examples, 135958 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:16:23,608 : INFO : EPOCH 1: training on 161599099 raw words (135843924 effective words) took 998.4s, 136057 effective words/s\n",
      "2022-10-19 18:16:25,518 : INFO : EPOCH 2 - PROGRESS: at 0.01% examples, 4376 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:21:25,743 : INFO : EPOCH 2 - PROGRESS: at 30.96% examples, 137066 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:26:25,750 : INFO : EPOCH 2 - PROGRESS: at 60.46% examples, 136326 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:31:25,770 : INFO : EPOCH 2 - PROGRESS: at 90.37% examples, 136105 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 18:33:00,992 : INFO : EPOCH 2: training on 161599099 raw words (135839212 effective words) took 997.4s, 136200 effective words/s\n",
      "2022-10-19 18:33:02,808 : INFO : EPOCH 3 - PROGRESS: at 0.01% examples, 4574 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:38:02,815 : INFO : EPOCH 3 - PROGRESS: at 30.87% examples, 136828 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 18:43:02,905 : INFO : EPOCH 3 - PROGRESS: at 60.34% examples, 136105 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 18:48:02,987 : INFO : EPOCH 3 - PROGRESS: at 90.30% examples, 136030 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 18:49:38,606 : INFO : EPOCH 3: training on 161599099 raw words (135842720 effective words) took 997.6s, 136170 effective words/s\n",
      "2022-10-19 18:49:40,753 : INFO : EPOCH 4 - PROGRESS: at 0.01% examples, 3839 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 18:54:40,802 : INFO : EPOCH 4 - PROGRESS: at 30.88% examples, 136676 words/s, in_qsize 59, out_qsize 1\n",
      "2022-10-19 18:59:40,820 : INFO : EPOCH 4 - PROGRESS: at 60.41% examples, 136203 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:04:40,841 : INFO : EPOCH 4 - PROGRESS: at 90.40% examples, 136151 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:06:15,851 : INFO : EPOCH 4: training on 161599099 raw words (135843835 effective words) took 997.2s, 136221 effective words/s\n",
      "2022-10-19 19:06:17,705 : INFO : EPOCH 5 - PROGRESS: at 0.01% examples, 4413 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:11:17,735 : INFO : EPOCH 5 - PROGRESS: at 30.76% examples, 136288 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:16:17,768 : INFO : EPOCH 5 - PROGRESS: at 60.21% examples, 135806 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:21:17,787 : INFO : EPOCH 5 - PROGRESS: at 90.05% examples, 135668 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 19:22:56,175 : INFO : EPOCH 5: training on 161599099 raw words (135843364 effective words) took 1000.3s, 135801 effective words/s\n",
      "2022-10-19 19:22:58,263 : INFO : EPOCH 6 - PROGRESS: at 0.01% examples, 3977 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 19:27:58,299 : INFO : EPOCH 6 - PROGRESS: at 30.83% examples, 136500 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:32:58,342 : INFO : EPOCH 6 - PROGRESS: at 60.13% examples, 135546 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 19:37:58,398 : INFO : EPOCH 6 - PROGRESS: at 90.01% examples, 135552 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:39:37,532 : INFO : EPOCH 6: training on 161599099 raw words (135836153 effective words) took 1001.3s, 135654 effective words/s\n",
      "2022-10-19 19:39:39,523 : INFO : EPOCH 7 - PROGRESS: at 0.01% examples, 4088 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:44:39,542 : INFO : EPOCH 7 - PROGRESS: at 30.80% examples, 136391 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:49:39,557 : INFO : EPOCH 7 - PROGRESS: at 60.15% examples, 135630 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 19:54:39,568 : INFO : EPOCH 7 - PROGRESS: at 89.95% examples, 135496 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 19:56:19,025 : INFO : EPOCH 7: training on 161599099 raw words (135834475 effective words) took 1001.5s, 135634 effective words/s\n",
      "2022-10-19 19:56:20,883 : INFO : EPOCH 8 - PROGRESS: at 0.01% examples, 4396 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 20:01:21,051 : INFO : EPOCH 8 - PROGRESS: at 30.78% examples, 136305 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 20:06:21,288 : INFO : EPOCH 8 - PROGRESS: at 60.20% examples, 135701 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:11:21,293 : INFO : EPOCH 8 - PROGRESS: at 90.07% examples, 135645 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:13:00,072 : INFO : EPOCH 8: training on 161599099 raw words (135842943 effective words) took 1001.0s, 135703 effective words/s\n",
      "2022-10-19 20:13:02,046 : INFO : EPOCH 9 - PROGRESS: at 0.01% examples, 4195 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 20:18:02,071 : INFO : EPOCH 9 - PROGRESS: at 30.78% examples, 136311 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:23:02,142 : INFO : EPOCH 9 - PROGRESS: at 60.17% examples, 135667 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:28:02,231 : INFO : EPOCH 9 - PROGRESS: at 90.00% examples, 135556 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 20:29:41,655 : INFO : EPOCH 9: training on 161599099 raw words (135837826 effective words) took 1001.6s, 135626 effective words/s\n",
      "2022-10-19 20:29:43,674 : INFO : EPOCH 10 - PROGRESS: at 0.01% examples, 4102 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:34:43,730 : INFO : EPOCH 10 - PROGRESS: at 30.82% examples, 136468 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:39:43,745 : INFO : EPOCH 10 - PROGRESS: at 60.11% examples, 135539 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:44:43,787 : INFO : EPOCH 10 - PROGRESS: at 89.87% examples, 135363 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:46:24,727 : INFO : EPOCH 10: training on 161599099 raw words (135837024 effective words) took 1003.1s, 135423 effective words/s\n",
      "2022-10-19 20:46:26,591 : INFO : EPOCH 11 - PROGRESS: at 0.01% examples, 4442 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 20:51:26,716 : INFO : EPOCH 11 - PROGRESS: at 30.66% examples, 135790 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 20:56:26,833 : INFO : EPOCH 11 - PROGRESS: at 60.02% examples, 135316 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 21:01:26,855 : INFO : EPOCH 11 - PROGRESS: at 89.69% examples, 135088 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 21:03:09,402 : INFO : EPOCH 11: training on 161599099 raw words (135839838 effective words) took 1004.7s, 135210 effective words/s\n",
      "2022-10-19 21:03:09,403 : INFO : Doc2Vec lifecycle event {'msg': 'training on 1939189188 raw words (1630084555 effective words) took 12024.4s, 135564 effective words/s', 'datetime': '2022-10-19T21:03:09.403641', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Train DBOW doc2vec\n",
    "# Report progress every 5 min.\n",
    "model_dbow299.train(documents299, total_examples=model_dbow299.corpus_count, epochs=model_dbow299.epochs, report_delay=5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 21:16:03,857 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-19T21:16:03.857502', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-19 21:16:03,858 : INFO : collecting all words and their counts\n",
      "2022-10-19 21:16:03,860 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-10-19 21:16:17,482 : INFO : PROGRESS: at example #100000, processed 13992516 words (1027257 words/s), 381557 word types, 4455 tags\n",
      "2022-10-19 21:16:31,389 : INFO : PROGRESS: at example #200000, processed 27656910 words (982648 words/s), 628044 word types, 4455 tags\n",
      "2022-10-19 21:16:45,748 : INFO : PROGRESS: at example #300000, processed 42317911 words (1021078 words/s), 840906 word types, 4455 tags\n",
      "2022-10-19 21:17:00,039 : INFO : PROGRESS: at example #400000, processed 56934419 words (1022843 words/s), 1031899 word types, 4455 tags\n",
      "2022-10-19 21:17:14,183 : INFO : PROGRESS: at example #500000, processed 71497702 words (1029737 words/s), 1210927 word types, 4455 tags\n",
      "2022-10-19 21:17:28,510 : INFO : PROGRESS: at example #600000, processed 86065791 words (1016892 words/s), 1379131 word types, 4455 tags\n",
      "2022-10-19 21:17:43,008 : INFO : PROGRESS: at example #700000, processed 100733999 words (1011800 words/s), 1540144 word types, 4455 tags\n",
      "2022-10-19 21:17:57,181 : INFO : PROGRESS: at example #800000, processed 115218760 words (1022019 words/s), 1695767 word types, 4455 tags\n",
      "2022-10-19 21:18:11,350 : INFO : PROGRESS: at example #900000, processed 129466311 words (1005621 words/s), 1845422 word types, 4455 tags\n",
      "2022-10-19 21:18:25,354 : INFO : PROGRESS: at example #1000000, processed 143889103 words (1029963 words/s), 1990569 word types, 4455 tags\n",
      "2022-10-19 21:18:39,222 : INFO : PROGRESS: at example #1100000, processed 158215458 words (1033114 words/s), 2132842 word types, 4455 tags\n",
      "2022-10-19 21:18:42,034 : INFO : collected 2160733 word types and 4455 unique tags from a corpus of 1119673 examples and 161060371 words\n",
      "2022-10-19 21:18:42,974 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=2, effective_min_count=5', 'datetime': '2022-10-19T21:18:42.974917', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 21:18:42,975 : INFO : Creating a fresh vocabulary\n",
      "2022-10-19 21:18:44,679 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 286533 unique words (13.26% of original 2160733, drops 1874200)', 'datetime': '2022-10-19T21:18:44.679080', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 21:18:44,680 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 158470276 word corpus (98.39% of original 161060371, drops 2590095)', 'datetime': '2022-10-19T21:18:44.680029', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 21:18:46,543 : INFO : deleting the raw counts dictionary of 2160733 items\n",
      "2022-10-19 21:18:46,577 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-10-19 21:18:46,577 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 123122259.23466939 word corpus (77.7%% of prior 158470276)', 'datetime': '2022-10-19T21:18:46.577874', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-19 21:18:50,032 : INFO : estimated required memory for 286533 words and 200 dimensions: 606174300 bytes\n",
      "2022-10-19 21:18:50,033 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n"
     ]
    }
   ],
   "source": [
    "model_dbow599 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "model_dbow599.build_vocab(documents599, progress_per=100000)\n",
    "print(model_dbow599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 21:18:50,259 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 30 workers on 286533 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-10-19T21:18:50.259471', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2022-10-19 21:18:52,367 : INFO : EPOCH 0 - PROGRESS: at 0.01% examples, 3920 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 21:23:52,381 : INFO : EPOCH 0 - PROGRESS: at 32.75% examples, 143335 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 21:28:52,416 : INFO : EPOCH 0 - PROGRESS: at 63.98% examples, 142423 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 21:33:52,503 : INFO : EPOCH 0 - PROGRESS: at 95.83% examples, 142311 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 21:34:30,982 : INFO : EPOCH 0: training on 161060371 raw words (133972441 effective words) took 940.7s, 142416 effective words/s\n",
      "2022-10-19 21:34:32,987 : INFO : EPOCH 1 - PROGRESS: at 0.01% examples, 4133 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 21:39:33,054 : INFO : EPOCH 1 - PROGRESS: at 32.60% examples, 142686 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 21:44:33,216 : INFO : EPOCH 1 - PROGRESS: at 63.83% examples, 142063 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 21:49:33,365 : INFO : EPOCH 1 - PROGRESS: at 95.60% examples, 141950 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 21:50:13,973 : INFO : EPOCH 1: training on 161060371 raw words (133970908 effective words) took 943.0s, 142072 effective words/s\n",
      "2022-10-19 21:50:15,955 : INFO : EPOCH 2 - PROGRESS: at 0.01% examples, 4177 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 21:55:16,045 : INFO : EPOCH 2 - PROGRESS: at 32.72% examples, 143191 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:00:16,078 : INFO : EPOCH 2 - PROGRESS: at 64.01% examples, 142509 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:05:16,111 : INFO : EPOCH 2 - PROGRESS: at 95.86% examples, 142385 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:05:54,327 : INFO : EPOCH 2: training on 161060371 raw words (133973565 effective words) took 940.3s, 142474 effective words/s\n",
      "2022-10-19 22:05:56,248 : INFO : EPOCH 3 - PROGRESS: at 0.01% examples, 4284 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 22:10:56,282 : INFO : EPOCH 3 - PROGRESS: at 32.67% examples, 143066 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:15:56,859 : INFO : EPOCH 3 - PROGRESS: at 63.97% examples, 142330 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:20:56,918 : INFO : EPOCH 3 - PROGRESS: at 95.81% examples, 142243 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 22:21:35,404 : INFO : EPOCH 3: training on 161060371 raw words (133976224 effective words) took 941.1s, 142368 effective words/s\n",
      "2022-10-19 22:21:37,256 : INFO : EPOCH 4 - PROGRESS: at 0.01% examples, 4551 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:26:37,270 : INFO : EPOCH 4 - PROGRESS: at 32.65% examples, 142999 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:31:37,290 : INFO : EPOCH 4 - PROGRESS: at 63.96% examples, 142453 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 22:36:37,427 : INFO : EPOCH 4 - PROGRESS: at 95.74% examples, 142225 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:37:16,591 : INFO : EPOCH 4: training on 161060371 raw words (133977653 effective words) took 941.2s, 142352 effective words/s\n",
      "2022-10-19 22:37:18,447 : INFO : EPOCH 5 - PROGRESS: at 0.01% examples, 4457 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:42:18,451 : INFO : EPOCH 5 - PROGRESS: at 32.63% examples, 142922 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:47:18,484 : INFO : EPOCH 5 - PROGRESS: at 63.88% examples, 142275 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:52:18,580 : INFO : EPOCH 5 - PROGRESS: at 95.74% examples, 142229 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 22:52:57,963 : INFO : EPOCH 5: training on 161060371 raw words (133976975 effective words) took 941.4s, 142323 effective words/s\n",
      "2022-10-19 22:52:59,878 : INFO : EPOCH 6 - PROGRESS: at 0.01% examples, 4329 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 22:57:59,888 : INFO : EPOCH 6 - PROGRESS: at 32.66% examples, 143025 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:02:59,915 : INFO : EPOCH 6 - PROGRESS: at 63.88% examples, 142245 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 23:07:59,960 : INFO : EPOCH 6 - PROGRESS: at 95.71% examples, 142189 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:08:39,683 : INFO : EPOCH 6: training on 161060371 raw words (133974320 effective words) took 941.7s, 142268 effective words/s\n",
      "2022-10-19 23:08:41,526 : INFO : EPOCH 7 - PROGRESS: at 0.01% examples, 4451 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 23:13:41,608 : INFO : EPOCH 7 - PROGRESS: at 32.59% examples, 142663 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:18:41,615 : INFO : EPOCH 7 - PROGRESS: at 63.85% examples, 142178 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:23:41,700 : INFO : EPOCH 7 - PROGRESS: at 95.56% examples, 141955 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:24:22,600 : INFO : EPOCH 7: training on 161060371 raw words (133973014 effective words) took 942.9s, 142085 effective words/s\n",
      "2022-10-19 23:24:24,417 : INFO : EPOCH 8 - PROGRESS: at 0.01% examples, 4616 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:29:24,506 : INFO : EPOCH 8 - PROGRESS: at 31.71% examples, 138763 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:34:24,520 : INFO : EPOCH 8 - PROGRESS: at 62.90% examples, 140027 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-19 23:39:24,568 : INFO : EPOCH 8 - PROGRESS: at 94.66% examples, 140623 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 23:40:14,291 : INFO : EPOCH 8: training on 161060371 raw words (133972706 effective words) took 951.7s, 140775 effective words/s\n",
      "2022-10-19 23:40:16,165 : INFO : EPOCH 9 - PROGRESS: at 0.01% examples, 4400 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 23:45:16,233 : INFO : EPOCH 9 - PROGRESS: at 32.60% examples, 142721 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 23:50:16,388 : INFO : EPOCH 9 - PROGRESS: at 63.76% examples, 141935 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 23:55:16,410 : INFO : EPOCH 9 - PROGRESS: at 95.51% examples, 141855 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-19 23:55:57,914 : INFO : EPOCH 9: training on 161060371 raw words (133972117 effective words) took 943.6s, 141978 effective words/s\n",
      "2022-10-19 23:56:00,074 : INFO : EPOCH 10 - PROGRESS: at 0.01% examples, 3795 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 00:01:00,142 : INFO : EPOCH 10 - PROGRESS: at 32.59% examples, 142520 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 00:06:00,175 : INFO : EPOCH 10 - PROGRESS: at 63.71% examples, 141800 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 00:11:00,188 : INFO : EPOCH 10 - PROGRESS: at 95.44% examples, 141736 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 00:11:42,629 : INFO : EPOCH 10: training on 161060371 raw words (133974050 effective words) took 944.7s, 141816 effective words/s\n",
      "2022-10-20 00:11:44,530 : INFO : EPOCH 11 - PROGRESS: at 0.01% examples, 4299 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 00:16:44,729 : INFO : EPOCH 11 - PROGRESS: at 32.48% examples, 142113 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 00:21:44,747 : INFO : EPOCH 11 - PROGRESS: at 63.57% examples, 141516 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 00:26:44,784 : INFO : EPOCH 11 - PROGRESS: at 95.16% examples, 141331 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 00:27:29,932 : INFO : EPOCH 11: training on 161060371 raw words (133971075 effective words) took 947.3s, 141426 effective words/s\n",
      "2022-10-20 00:27:29,933 : INFO : Doc2Vec lifecycle event {'msg': 'training on 1932724452 raw words (1607685048 effective words) took 11319.7s, 142026 effective words/s', 'datetime': '2022-10-20T00:27:29.933426', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model_dbow599 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "model_dbow599.build_vocab(documents599, progress_per=100000)\n",
    "print(model_dbow599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 01:38:29,164 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-20T01:38:29.164632', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-20 01:38:29,202 : INFO : collecting all words and their counts\n",
      "2022-10-20 01:38:29,204 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-10-20 01:38:42,739 : INFO : PROGRESS: at example #100000, processed 13978134 words (1032729 words/s), 379245 word types, 1749 tags\n",
      "2022-10-20 01:38:56,555 : INFO : PROGRESS: at example #200000, processed 27666763 words (990871 words/s), 624354 word types, 1749 tags\n",
      "2022-10-20 01:39:10,646 : INFO : PROGRESS: at example #300000, processed 42319066 words (1039897 words/s), 836069 word types, 1749 tags\n",
      "2022-10-20 01:39:24,941 : INFO : PROGRESS: at example #400000, processed 56912252 words (1020931 words/s), 1025592 word types, 1749 tags\n",
      "2022-10-20 01:39:39,269 : INFO : PROGRESS: at example #500000, processed 71473221 words (1016345 words/s), 1203216 word types, 1749 tags\n",
      "2022-10-20 01:39:53,334 : INFO : PROGRESS: at example #600000, processed 86044969 words (1036101 words/s), 1370573 word types, 1749 tags\n",
      "2022-10-20 01:40:07,797 : INFO : PROGRESS: at example #700000, processed 100702548 words (1013514 words/s), 1530628 word types, 1749 tags\n",
      "2022-10-20 01:40:21,928 : INFO : PROGRESS: at example #800000, processed 115185653 words (1024962 words/s), 1685289 word types, 1749 tags\n",
      "2022-10-20 01:40:35,978 : INFO : PROGRESS: at example #900000, processed 129405191 words (1012078 words/s), 1833607 word types, 1749 tags\n",
      "2022-10-20 01:40:50,074 : INFO : PROGRESS: at example #1000000, processed 143843331 words (1024379 words/s), 1978042 word types, 1749 tags\n",
      "2022-10-20 01:41:04,251 : INFO : PROGRESS: at example #1100000, processed 158149351 words (1009162 words/s), 2119896 word types, 1749 tags\n",
      "2022-10-20 01:41:06,227 : INFO : collected 2139304 word types and 1749 unique tags from a corpus of 1113915 examples and 160170076 words\n",
      "2022-10-20 01:41:07,183 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=2, effective_min_count=5', 'datetime': '2022-10-20T01:41:07.183100', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-20 01:41:07,184 : INFO : Creating a fresh vocabulary\n",
      "2022-10-20 01:41:08,973 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 283895 unique words (13.27% of original 2139304, drops 1855409)', 'datetime': '2022-10-20T01:41:08.973142', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-20 01:41:08,974 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 157605613 word corpus (98.40% of original 160170076, drops 2564463)', 'datetime': '2022-10-20T01:41:08.974257', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-20 01:41:10,853 : INFO : deleting the raw counts dictionary of 2139304 items\n",
      "2022-10-20 01:41:10,888 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-10-20 01:41:10,888 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 122431306.59300278 word corpus (77.7%% of prior 157605613)', 'datetime': '2022-10-20T01:41:10.888814', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-20 01:41:14,274 : INFO : estimated required memory for 283895 words and 100 dimensions: 370112900 bytes\n",
      "2022-10-20 01:41:14,275 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>\n"
     ]
    }
   ],
   "source": [
    "model_dbow1499 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=100, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "model_dbow1499.build_vocab(documents1499, progress_per=100000)\n",
    "print(model_dbow1499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 01:41:21,812 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 30 workers on 283895 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-10-20T01:41:21.812708', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2022-10-20 01:41:23,639 : INFO : EPOCH 0 - PROGRESS: at 0.01% examples, 4395 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 01:46:23,651 : INFO : EPOCH 0 - PROGRESS: at 39.03% examples, 167929 words/s, in_qsize 60, out_qsize 1\n",
      "2022-10-20 01:51:23,675 : INFO : EPOCH 0 - PROGRESS: at 76.80% examples, 167449 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 01:54:24,128 : INFO : EPOCH 0: training on 160170076 raw words (131030834 effective words) took 782.3s, 167496 effective words/s\n",
      "2022-10-20 01:54:25,844 : INFO : EPOCH 1 - PROGRESS: at 0.01% examples, 4734 words/s, in_qsize 60, out_qsize 1\n",
      "2022-10-20 01:59:25,896 : INFO : EPOCH 1 - PROGRESS: at 38.85% examples, 167166 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 02:04:25,905 : INFO : EPOCH 1 - PROGRESS: at 76.36% examples, 166507 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:07:30,808 : INFO : EPOCH 1: training on 160170076 raw words (131030798 effective words) took 786.7s, 166568 effective words/s\n",
      "2022-10-20 02:07:32,549 : INFO : EPOCH 2 - PROGRESS: at 0.01% examples, 4656 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 02:12:32,558 : INFO : EPOCH 2 - PROGRESS: at 38.89% examples, 167388 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 02:17:32,623 : INFO : EPOCH 2 - PROGRESS: at 76.67% examples, 167173 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:20:33,457 : INFO : EPOCH 2: training on 160170076 raw words (131032838 effective words) took 782.6s, 167428 effective words/s\n",
      "2022-10-20 02:20:35,118 : INFO : EPOCH 3 - PROGRESS: at 0.01% examples, 4816 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:25:35,144 : INFO : EPOCH 3 - PROGRESS: at 39.09% examples, 168276 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:30:35,159 : INFO : EPOCH 3 - PROGRESS: at 76.89% examples, 167697 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 02:33:35,144 : INFO : EPOCH 3: training on 160170076 raw words (131032725 effective words) took 781.7s, 167631 effective words/s\n",
      "2022-10-20 02:33:36,748 : INFO : EPOCH 4 - PROGRESS: at 0.01% examples, 4999 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 02:38:36,847 : INFO : EPOCH 4 - PROGRESS: at 38.88% examples, 167345 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:43:36,850 : INFO : EPOCH 4 - PROGRESS: at 76.70% examples, 167276 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:46:38,716 : INFO : EPOCH 4: training on 160170076 raw words (131031971 effective words) took 783.6s, 167226 effective words/s\n",
      "2022-10-20 02:46:40,391 : INFO : EPOCH 5 - PROGRESS: at 0.01% examples, 4855 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:51:40,470 : INFO : EPOCH 5 - PROGRESS: at 38.83% examples, 167081 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:56:40,488 : INFO : EPOCH 5 - PROGRESS: at 76.39% examples, 166549 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 02:59:44,081 : INFO : EPOCH 5: training on 160170076 raw words (131025818 effective words) took 785.4s, 166837 effective words/s\n",
      "2022-10-20 02:59:45,783 : INFO : EPOCH 6 - PROGRESS: at 0.01% examples, 4743 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 03:04:45,888 : INFO : EPOCH 6 - PROGRESS: at 38.87% examples, 167202 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 03:09:45,889 : INFO : EPOCH 6 - PROGRESS: at 76.78% examples, 167404 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 03:12:46,094 : INFO : EPOCH 6: training on 160170076 raw words (131028578 effective words) took 782.0s, 167556 effective words/s\n",
      "2022-10-20 03:12:47,824 : INFO : EPOCH 7 - PROGRESS: at 0.01% examples, 4811 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:17:47,843 : INFO : EPOCH 7 - PROGRESS: at 39.19% examples, 168695 words/s, in_qsize 58, out_qsize 2\n",
      "2022-10-20 03:22:47,845 : INFO : EPOCH 7 - PROGRESS: at 77.09% examples, 168113 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:25:45,555 : INFO : EPOCH 7: training on 160170076 raw words (131031969 effective words) took 779.4s, 168109 effective words/s\n",
      "2022-10-20 03:25:47,029 : INFO : EPOCH 8 - PROGRESS: at 0.01% examples, 5563 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:30:47,090 : INFO : EPOCH 8 - PROGRESS: at 39.05% examples, 168178 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:35:47,200 : INFO : EPOCH 8 - PROGRESS: at 76.94% examples, 167825 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:38:46,201 : INFO : EPOCH 8: training on 160170076 raw words (131035846 effective words) took 780.6s, 167859 effective words/s\n",
      "2022-10-20 03:38:47,925 : INFO : EPOCH 9 - PROGRESS: at 0.01% examples, 4638 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:43:47,936 : INFO : EPOCH 9 - PROGRESS: at 38.95% examples, 167626 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:48:48,013 : INFO : EPOCH 9 - PROGRESS: at 76.78% examples, 167408 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:51:48,625 : INFO : EPOCH 9: training on 160170076 raw words (131031441 effective words) took 782.4s, 167471 effective words/s\n",
      "2022-10-20 03:51:50,232 : INFO : EPOCH 10 - PROGRESS: at 0.01% examples, 5107 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 03:56:50,378 : INFO : EPOCH 10 - PROGRESS: at 39.00% examples, 167859 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-20 04:01:50,405 : INFO : EPOCH 10 - PROGRESS: at 76.69% examples, 167215 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 04:04:51,374 : INFO : EPOCH 10: training on 160170076 raw words (131031654 effective words) took 782.7s, 167402 effective words/s\n",
      "2022-10-20 04:04:53,127 : INFO : EPOCH 11 - PROGRESS: at 0.01% examples, 4576 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 04:09:53,242 : INFO : EPOCH 11 - PROGRESS: at 39.07% examples, 168101 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 04:14:53,351 : INFO : EPOCH 11 - PROGRESS: at 76.82% examples, 167457 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-20 04:17:54,002 : INFO : EPOCH 11: training on 160170076 raw words (131035174 effective words) took 782.6s, 167433 effective words/s\n",
      "2022-10-20 04:17:54,004 : INFO : Doc2Vec lifecycle event {'msg': 'training on 1922040912 raw words (1572379646 effective words) took 9392.2s, 167414 effective words/s', 'datetime': '2022-10-20T04:17:54.004225', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model_dbow1499.train(documents1499, total_examples=model_dbow1499.corpus_count, epochs=model_dbow1499.epochs, report_delay=5*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_dbow299, model_dbow599, model_dbow1499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "[('q-learning', 0.9207262992858887),\n",
      " ('temporal difference learning', 0.8835273385047913),\n",
      " ('error-driven learning', 0.8363973498344421),\n",
      " ('action selection', 0.8000704050064087),\n",
      " ('reinforcement', 0.7967041730880737),\n",
      " ('learning classifier system', 0.7761959433555603),\n",
      " ('markov decision process', 0.7275181412696838),\n",
      " ('partially observable markov decision process', 0.6965964436531067),\n",
      " ('value function', 0.6812279224395752),\n",
      " ('robot learning', 0.6616670489311218),\n",
      " ('bellman equation', 0.6610139608383179),\n",
      " ('sequence learning', 0.6240488290786743),\n",
      " ('optimal policy', 0.6211299896240234),\n",
      " ('learning', 0.6179113984107971),\n",
      " ('active learning (machine learning)', 0.6147891283035278)]\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "[('learning classifier system', 0.7715908885002136),\n",
      " ('markov decision process', 0.732695460319519),\n",
      " ('partially observable markov decision process', 0.7013351917266846),\n",
      " ('robot learning', 0.6769681572914124),\n",
      " ('value function', 0.6766259670257568),\n",
      " ('bellman equation', 0.6470258831977844),\n",
      " ('learning', 0.6300797462463379),\n",
      " ('function approximation', 0.6175116300582886),\n",
      " ('multi-task learning', 0.6046625375747681),\n",
      " ('active learning (machine learning)', 0.5986279249191284),\n",
      " ('online machine learning', 0.5952551364898682),\n",
      " ('unsupervised learning', 0.5908072590827942),\n",
      " ('autonomous agent', 0.5907966494560242),\n",
      " ('wake-sleep algorithm', 0.5890874862670898),\n",
      " ('instance-based learning', 0.5711029767990112)]\n",
      "Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>\n",
      "[('robot learning', 0.7575361728668213),\n",
      " ('markov decision process', 0.7548259496688843),\n",
      " ('active learning (machine learning)', 0.7051279544830322),\n",
      " ('autonomous agent', 0.6690660119056702),\n",
      " ('unsupervised learning', 0.6248951554298401),\n",
      " ('function approximation', 0.6237279772758484),\n",
      " ('learning artificial intelligence', 0.6148892641067505),\n",
      " ('semi-supervised learning', 0.6003302931785583),\n",
      " ('machine learning', 0.5957800149917603),\n",
      " ('state space', 0.5891668200492859),\n",
      " ('supervised learning', 0.5829219818115234),\n",
      " ('robot', 0.5761703252792358),\n",
      " ('social robot', 0.5692980289459229),\n",
      " ('intelligent agent', 0.5662297010421753),\n",
      " ('robotics', 0.5621621012687683)]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    pprint(model.dv.most_similar(positive=[\"reinforcement learning\"], topn=15))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying the UML class diagram in the performance analysis  This paper covers the performance parameters for an object= oriented software system: The number of classes in the class diagram of this system, the number of attributes and methods in each class, their data types, the multiplicities of single classes, the number of relationships in this diagram, the types and multiplicities of relationships, the lengths of access paths, and the allocation of methods and attributes to classes. A performance analysis is described. It treats a class diagram, which must be in attendance at each analysis because used dynamic diagrams must be consistent with it, and encloses these parameters. It is based on an approach which enables one to predict the performance values of response time, throughput and utilization, for use cases that can operate on databases related to this diagram\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('class diagram', 0.45280298590660095)\n",
      "('flowchart', 0.4430471956729889)\n",
      "('state diagram', 0.4362097978591919)\n",
      "('diagram', 0.4313512146472931)\n",
      "('unified modeling language', 0.4254407584667206)\n",
      "('uml', 0.42517900466918945)\n",
      "('object-oriented programming', 0.42255598306655884)\n",
      "('object oriented languages', 0.41865208745002747)\n",
      "('object oriented programming', 0.4178245961666107)\n",
      "('object-oriented design', 0.4157467186450958)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('class diagram', 0.43773671984672546)\n",
      "('diagram', 0.43379321694374084)\n",
      "('state diagram', 0.4248395264148712)\n",
      "('object-oriented design', 0.42466309666633606)\n",
      "('object oriented', 0.42016956210136414)\n",
      "('object-oriented programming', 0.4160917401313782)\n",
      "('object oriented design', 0.40973660349845886)\n",
      "('object oriented programming', 0.40673404932022095)\n",
      "('unified modeling language', 0.4038653075695038)\n",
      "('uml', 0.39547809958457947)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>\n",
      "('object-oriented programming', 0.49014148116111755)\n",
      "('unified modeling language', 0.48571857810020447)\n",
      "('object oriented', 0.4834008812904358)\n",
      "('object oriented programming', 0.47327327728271484)\n",
      "('notation', 0.46607860922813416)\n",
      "('system modeling', 0.4634566605091095)\n",
      "('metamodeling', 0.4392932951450348)\n",
      "('modeling language', 0.42887839674949646)\n",
      "('modeling', 0.4226897358894348)\n",
      "('software design', 0.41678282618522644)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'access path',\n",
       " 'algorithm',\n",
       " 'class diagram',\n",
       " 'communication diagram',\n",
       " 'composite structure diagram',\n",
       " 'computer science',\n",
       " 'data type',\n",
       " 'dynamic diagram',\n",
       " 'oriented software system',\n",
       " 'performance analysis',\n",
       " 'performance parameter',\n",
       " 'performance value',\n",
       " 'response time',\n",
       " 'sequence diagram',\n",
       " 'single class',\n",
       " 'system context diagram',\n",
       " 'system sequence diagram',\n",
       " 'theoretical computer science',\n",
       " 'timing diagram',\n",
       " 'uml class diagram',\n",
       " 'use case',\n",
       " 'use case diagram'}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_articles.text[0]\n",
    "print(text)\n",
    "print('\\n')\n",
    "for model in  models:\n",
    "    print(model)\n",
    "    doc_vector = model.infer_vector(text.split())\n",
    "    sims = model.dv.most_similar([doc_vector], topn=10)\n",
    "    print('\\n'.join(map(str,sims)))\n",
    "    print('\\n')\n",
    "# оригинальные теги из датасета\n",
    "set(topic.lower() for topic in test_articles.keywords[0] + test_articles.fos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Requirements? Well, That Depends  Using scenarios can help you quantify your requirements. Scenarios make requirements quantification easier by describing and restricting the context necessary for quantification.\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('user needs', 0.5663952827453613)\n",
      "('usable', 0.5588348507881165)\n",
      "('programming language', 0.5476263165473938)\n",
      "('documentation', 0.5468922853469849)\n",
      "('ask price', 0.5420323610305786)\n",
      "('user interface', 0.5368489027023315)\n",
      "('software engineering', 0.5357776284217834)\n",
      "('better understanding', 0.5351817607879639)\n",
      "('software engineer', 0.5344774127006531)\n",
      "('as is', 0.5340394377708435)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('software engineering', 0.5559115409851074)\n",
      "('position paper', 0.5510293841362)\n",
      "('better understanding', 0.5479234457015991)\n",
      "('usable', 0.5449410080909729)\n",
      "('documentation', 0.5432483553886414)\n",
      "('user interface', 0.5380824208259583)\n",
      "('programming language', 0.5376284122467041)\n",
      "('internet privacy', 0.5290253162384033)\n",
      "('ask price', 0.5274795889854431)\n",
      "('user-centered design', 0.5268582105636597)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>\n",
      "('usable', 0.6586560010910034)\n",
      "('documentation', 0.6249518394470215)\n",
      "('best practice', 0.614913284778595)\n",
      "('software', 0.6084707975387573)\n",
      "('software engineering', 0.6075769662857056)\n",
      "('computer science', 0.6046652793884277)\n",
      "('user interface', 0.5944244861602783)\n",
      "('programming language', 0.5919371843338013)\n",
      "('usability', 0.5904869437217712)\n",
      "('end user', 0.588432788848877)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'computer science',\n",
       " 'formal specification',\n",
       " 'goal modeling',\n",
       " 'requirement',\n",
       " 'requirements',\n",
       " 'software engineering',\n",
       " 'systems engineering',\n",
       " 'use case'}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_articles.text[11]\n",
    "print(text)\n",
    "print('\\n')\n",
    "for model in models:\n",
    "    print(model)\n",
    "    doc_vector = model.infer_vector(text.split())\n",
    "    sims = model.dv.most_similar([doc_vector], topn=10)\n",
    "    print('\\n'.join(map(str,sims)))\n",
    "    print('\\n')\n",
    "    \n",
    "# оригинальные теги из датасета\n",
    "set(topic.lower() for topic in test_articles.keywords[11] + test_articles.fos[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examplers based image fusion features for face recognition    Examplers of a face are formed from multiple gallery images of a person and are used in the process of classification of a test image. We incorporate such examplers in forming a biologically inspired local binary decisions on similarity based face recognition method. As opposed to single model approaches such as face averages the exampler based approach results in higher recognition accu- racies and stability. Using multiple training samples per person, the method shows the following recognition accuracies: 99.0% on AR, 99.5% on FERET, 99.5% on ORL, 99.3% on EYALE, 100.0% on YALE and 100.0% on CALTECH face databases. In addition to face recognition, the method also detects the natural variability in the face images which can find application in automatic tagging of face images. \n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('face recognition', 0.5977910757064819)\n",
      "('face detection', 0.5977813601493835)\n",
      "('image recognition', 0.5968683958053589)\n",
      "('facial recognition system', 0.5940918922424316)\n",
      "('feature extraction', 0.5668507218360901)\n",
      "('object-class detection', 0.566740095615387)\n",
      "('three-dimensional face recognition', 0.56371009349823)\n",
      "('biometrics', 0.5598182082176208)\n",
      "('recognition rate', 0.5584964752197266)\n",
      "('face', 0.5567355751991272)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('face detection', 0.6194691061973572)\n",
      "('face recognition', 0.6041358113288879)\n",
      "('facial recognition system', 0.6027971506118774)\n",
      "('image recognition', 0.5892899036407471)\n",
      "('three-dimensional face recognition', 0.5846549272537231)\n",
      "('object-class detection', 0.5793598294258118)\n",
      "('face', 0.5626608729362488)\n",
      "('feature extraction', 0.5554215908050537)\n",
      "('biometrics', 0.5326582193374634)\n",
      "('gabor filter', 0.5288644433021545)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>\n",
      "('face detection', 0.7324872612953186)\n",
      "('facial recognition system', 0.7314546704292297)\n",
      "('face recognition', 0.727556586265564)\n",
      "('image recognition', 0.7269341945648193)\n",
      "('feature extraction', 0.6947646141052246)\n",
      "('face', 0.6914364695549011)\n",
      "('biometrics', 0.6635975241661072)\n",
      "('template matching', 0.6463118195533752)\n",
      "('image matching', 0.6334623098373413)\n",
      "('feature (computer vision)', 0.6279011964797974)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'artificial intelligence',\n",
       " 'computer science',\n",
       " 'computer vision',\n",
       " 'face detection',\n",
       " 'face recognition',\n",
       " 'facial recognition system',\n",
       " 'feret',\n",
       " 'image fusion',\n",
       " 'natural variability',\n",
       " 'object-class detection',\n",
       " 'pattern recognition',\n",
       " 'standard test image',\n",
       " 'three-dimensional face recognition'}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_articles.text[33]\n",
    "print(text)\n",
    "print('\\n')\n",
    "for model in models:\n",
    "    print(model)\n",
    "    doc_vector = model.infer_vector(text.split())\n",
    "    sims = model.dv.most_similar([doc_vector], topn=10)\n",
    "    print('\\n'.join(map(str,sims)))\n",
    "    print('\\n')\n",
    "# оригинальные теги из датасета\n",
    "set(topic.lower() for topic in test_articles.keywords[33] + test_articles.fos[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teaching an Agent to Test Students International Conference on Machine Learning This paper presents an innovative application of the Disciple Learning Agent Shell to the building of an educational agent that generates history tests for middle school students, to assist in the assessment of their understanding and use of higher-order thinking skills. Disciple has been taught by an educator to generate and answer basic test questions and to explain the answers. From its interaction with the educational expert, Disciple has learned general rules that allow it to generate a large number of new test questions for students, together with hints, answers, and exp- lanations of the answers. As a result, it can guide the students during their practice of higher-order thinking skills as they would be directly guided by the educator. It can also be used by the edu- cator to generate a different exam for each student in the class. Disciple has been experimentally evaluated by history experts, students and tea-chers, with very promising results. The work on developing this educational agent illustrates an integration of machine learning, knowledge acquisition, problem solving and intelligent tu-toring systems in the context of computer-based assessment involving multimedia documents.\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('tutor', 0.5805657505989075)\n",
      "('education system', 0.564991295337677)\n",
      "('distance education', 0.5437965393066406)\n",
      "('e learning', 0.5401960611343384)\n",
      "('higher education', 0.5392137765884399)\n",
      "('e-learning', 0.5390357971191406)\n",
      "('computer literacy', 0.5349887609481812)\n",
      "('teaching', 0.5336994528770447)\n",
      "('distance learning', 0.5291029214859009)\n",
      "('mathematics education', 0.5284370183944702)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('tutor', 0.5599042773246765)\n",
      "('e learning', 0.5380202531814575)\n",
      "('intelligent tutoring system', 0.5340824723243713)\n",
      "('teaching', 0.5259371995925903)\n",
      "('e-learning', 0.5215306878089905)\n",
      "('competence (human resources)', 0.5213937163352966)\n",
      "('distance learning', 0.5206841230392456)\n",
      "('learning environment', 0.5172141790390015)\n",
      "('distance education', 0.5165669322013855)\n",
      "('computer literacy', 0.5151674747467041)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>\n",
      "('distance education', 0.6170822978019714)\n",
      "('curriculum', 0.5853152871131897)\n",
      "('educational technology', 0.5852523446083069)\n",
      "('computer aided instruction', 0.5841845870018005)\n",
      "('mathematics education', 0.5801143050193787)\n",
      "('computer science education', 0.5792379975318909)\n",
      "('experiential learning', 0.5771450400352478)\n",
      "('higher education', 0.5768502950668335)\n",
      "('hypermedia', 0.5767821073532104)\n",
      "('multimedia', 0.5767455697059631)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'computer science',\n",
       " 'higher order',\n",
       " 'knowledge acquisition',\n",
       " 'learning agent',\n",
       " 'machine learning',\n",
       " 'mathematics education',\n",
       " 'test students',\n",
       " 'thinking skills'}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_articles.text[77]\n",
    "print(text)\n",
    "print('\\n')\n",
    "for model in models:\n",
    "    print(model)\n",
    "    doc_vector = model.infer_vector(text.split())\n",
    "    sims = model.dv.most_similar([doc_vector], topn=10)\n",
    "    print('\\n'.join(map(str,sims)))\n",
    "    print('\\n')\n",
    "# оригинальные теги из датасета\n",
    "set(topic.lower() for topic in test_articles.keywords[77] + test_articles.fos[77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing modular polynomials in quasi-linear time  We analyse and compare the complexity of several algorithms for computing modular polynomials. Under the assumption that rounding errors do not influence the correctness of the result, which appears to be satisfied in practice, we show that an algorithm relying on floating point evaluation of modular functions and on interpolation has a complexity that is up to logarithmic factors linear in the size of the computed polynomials. In particular, it obtains the classical modular polynomial Phi(l) of prime level l in time O (l(2) log(3) l M(l)) subset of O (l(3) log(4+epsilon) l), where M(l) is the time needed to multiply two l-bit numbers. Besides treating modular polynomials for Gamma(0)(l), which are an important ingredient in many algorithms dealing with isogenies of elliptic curves, the algorithm is easily adapted to more general situations. Composite levels are handled just as easily as prime levels, as well as polynomials between a modular function and its transform of prime level, such as the Schlafli polynomials and their generalisations. Our distributed implementation of the algorithm confirms the theoretical analysis by computing modular equations of record level around 10000 in less than two weeks on ten processors.\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('multiplication', 0.5197780728340149)\n",
      "('modular arithmetic', 0.5118243098258972)\n",
      "('exponentiation', 0.5091626644134521)\n",
      "('polynomial', 0.5084396600723267)\n",
      "('arithmetic function', 0.5045469999313354)\n",
      "('prime factor', 0.5038449168205261)\n",
      "('finite field', 0.5031833052635193)\n",
      "('modular exponentiation', 0.4947267770767212)\n",
      "('irreducible polynomial', 0.49431130290031433)\n",
      "('prime number', 0.4911862909793854)\n",
      "('complex number', 0.4899396598339081)\n",
      "('arithmetic', 0.48610979318618774)\n",
      "('degree of a polynomial', 0.48003312945365906)\n",
      "('modulo', 0.4752838909626007)\n",
      "('reciprocal polynomial', 0.46671929955482483)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "('polynomial', 0.5194013118743896)\n",
      "('multiplication', 0.5056099891662598)\n",
      "('finite field', 0.5010773539543152)\n",
      "('prime (order theory)', 0.4970301687717438)\n",
      "('number theory', 0.4721587896347046)\n",
      "('modulo', 0.4710817039012909)\n",
      "('arithmetic', 0.4665812849998474)\n",
      "('matrix polynomial', 0.46335944533348083)\n",
      "('integer', 0.450157105922699)\n",
      "('discrete logarithm', 0.4362308382987976)\n",
      "('elliptic curve cryptography', 0.43378108739852905)\n",
      "('circuit complexity', 0.4311591386795044)\n",
      "('algebraic number', 0.42994290590286255)\n",
      "('time complexity', 0.41876134276390076)\n",
      "('elliptic curve', 0.41818785667419434)\n",
      "\n",
      "\n",
      "Doc2Vec<dbow+w,d100,n5,w8,mc5,s0.001,t30>\n",
      "('polynomial', 0.6096795201301575)\n",
      "('multiplication', 0.5999065041542053)\n",
      "('arithmetic', 0.5804797410964966)\n",
      "('algebraic number', 0.5375460982322693)\n",
      "('finite field', 0.5354934930801392)\n",
      "('integer', 0.5333006381988525)\n",
      "('logarithm', 0.5206108689308167)\n",
      "('boolean function', 0.513774037361145)\n",
      "('time complexity', 0.5131105780601501)\n",
      "('prime (order theory)', 0.5123334527015686)\n",
      "('binary logarithm', 0.5096869468688965)\n",
      "('discrete mathematics', 0.5044398307800293)\n",
      "('combinatorics', 0.4829178750514984)\n",
      "('mathematical proof', 0.48279961943626404)\n",
      "('complexity', 0.47970443964004517)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'calculus',\n",
       " 'computational complexity',\n",
       " 'difference polynomials',\n",
       " 'discrete mathematics',\n",
       " 'elliptic curve',\n",
       " 'floating point',\n",
       " 'interpolation',\n",
       " 'linear time',\n",
       " 'macdonald polynomials',\n",
       " 'mathematics',\n",
       " 'modular equation',\n",
       " 'modular form',\n",
       " 'modular function',\n",
       " 'number theory',\n",
       " 'polynomial',\n",
       " 'prime (order theory)',\n",
       " 'time complexity'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = test_articles.text[555]\n",
    "print(text)\n",
    "print('\\n')\n",
    "for model in models:\n",
    "    print(model)\n",
    "    doc_vector = model.infer_vector(text.split())\n",
    "    sims = model.dv.most_similar([doc_vector], topn=15)\n",
    "    print('\\n'.join(map(str,sims)))\n",
    "    print('\\n')\n",
    "# оригинальные теги из датасета\n",
    "set(topic.lower() for topic in test_articles.keywords[555] + test_articles.fos[555])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 04:22:55,842 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_dbow299.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-20T04:22:55.842525', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2022-10-20 04:22:55,858 : INFO : storing np array 'vectors' to doc2vec_dbow299.model.wv.vectors.npy\n",
      "2022-10-20 04:22:55,972 : INFO : storing np array 'syn1neg' to doc2vec_dbow299.model.syn1neg.npy\n",
      "2022-10-20 04:22:56,083 : INFO : not storing attribute cum_table\n",
      "2022-10-20 04:22:56,236 : INFO : saved doc2vec_dbow299.model\n",
      "2022-10-20 04:22:56,237 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_dbow599.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-20T04:22:56.237580', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2022-10-20 04:22:56,238 : INFO : storing np array 'vectors' to doc2vec_dbow599.model.wv.vectors.npy\n",
      "2022-10-20 04:22:56,354 : INFO : storing np array 'syn1neg' to doc2vec_dbow599.model.syn1neg.npy\n",
      "2022-10-20 04:22:56,465 : INFO : not storing attribute cum_table\n",
      "2022-10-20 04:22:56,609 : INFO : saved doc2vec_dbow599.model\n",
      "2022-10-20 04:22:56,610 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_dbow1499.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-20T04:22:56.610611', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2022-10-20 04:22:56,611 : INFO : storing np array 'vectors' to doc2vec_dbow1499.model.wv.vectors.npy\n",
      "2022-10-20 04:22:56,673 : INFO : storing np array 'syn1neg' to doc2vec_dbow1499.model.syn1neg.npy\n",
      "2022-10-20 04:22:56,724 : INFO : not storing attribute cum_table\n",
      "2022-10-20 04:22:56,866 : INFO : saved doc2vec_dbow1499.model\n"
     ]
    }
   ],
   "source": [
    "model_dbow299.save('doc2vec_dbow299.model')\n",
    "model_dbow599.save('doc2vec_dbow599.model')\n",
    "model_dbow1499.save('doc2vec_dbow1499.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only fos for topics?\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue your doc2vec explorations, refer to the official API documentation in Gensim: https://radimrehurek.com/gensim/models/doc2vec.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
